{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chckall.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OdtZdyMmqJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import imutils\n",
        "from imutils.video import VideoStream, FileVideoStream, FPS\n",
        "import time\n",
        "from operations import predict_image, facedetect\n",
        "from operations import social_distancing_config as config\n",
        "from operations.detection import detect_people\n",
        "from scipy.spatial import distance as dist\n",
        "from datetime import datetime\n",
        "\n",
        "#loading face detection model\n",
        "prototxtPath = \"./face_detector/deploy.prototxt\"\n",
        "weightsPath = \"./face_detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
        "\n",
        "st.write('# Face Mask Image Detector')\n",
        "\n",
        "#input video stream\n",
        "input_video = \"./videos/test/test_01.mp4\"\n",
        "\n",
        "#create output dir if not exists for storing recorded videos\n",
        "output_dir = \"./videos/output\"\n",
        "if not os.path.isdir(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "\n",
        "uploaded_image = st.sidebar.file_uploader(\"Choose a JPG file\", type=\"jpg\")\n",
        "confidence_value = st.sidebar.slider('Confidence:', 0.0, 1.0, 0.5, 0.1)\n",
        "if uploaded_image:\n",
        "    st.sidebar.info('Uploaded image:')\n",
        "    st.sidebar.image(uploaded_image, width=240)\n",
        "    grad_cam_button = st.sidebar.button('Grad CAM')\n",
        "    patch_size_value = st.sidebar.slider('Patch size:', 10, 90, 20, 10)\n",
        "    occlusion_sensitivity_button = st.sidebar.button('Occlusion Sensitivity')\n",
        "    frame = cv2.imdecode(np.fromstring(uploaded_image.read(), np.uint8), 1)\n",
        "    frame = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    orig = image.copy()\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "\t#detect face and coordinates of face\n",
        "\t(faces, locs) = facedetect.detect_face(frame, faceNet)\n",
        "\n",
        "\tif faces is None:\n",
        "\t\tpass\n",
        "\t\n",
        "\t#check if face is detected\n",
        "\telif faces:\n",
        "\t\tfor (face, box) in zip(faces, locs):\n",
        "\t\t\t# unpack the bounding box and predictions\n",
        "\t\t\t(startX, startY, endX, endY) = box\n",
        "\t\t\t#get the prediction of mask\n",
        "\t\t\tdata = predict_image.main(face)\n",
        "\n",
        "\t\t\ttext = data[0][\"res\"]\n",
        "\t\t\tpercentage = data[1]\n",
        "\t\t\tkey_list = list(percentage.keys())\n",
        "\t\t\tfor key, value in percentage.items():\n",
        "\t\t\t\ttext = text.title()# Title Case looks Stunning.\n",
        "\t\t\t\tcolor = (0, 255, 0) if text == \"Mask\" else (0, 0, 255)\n",
        "\t\t\t\tindex = int(key_list.index(key)-1)\n",
        "\t\t\t\tcv2.putText(frame, text, (startX, startY - 10),\n",
        "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\t\t\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "\t#detect people\n",
        "\tresults = detect_people(frame)\n",
        "\n",
        "\tif results is None:\n",
        "\t\tpass\n",
        "\n",
        "\telif results:\n",
        "\n",
        "\t\t# initialize the set of indexes that violate the minimum social\n",
        "\t\t# distance\n",
        "\t\tviolate = set()\n",
        "\n",
        "\t\t# ensure there are *at least* two people detections (required in\n",
        "\t\t# order to compute our pairwise distance maps)\n",
        "\t\tif len(results) >= 2:\n",
        "\t\t\t# extract all centroids from the results and compute the\n",
        "\t\t\t# Euclidean distances between all pairs of the centroids\n",
        "\t\t\tcentroids = np.array([r[2] for r in results])\n",
        "\t\t\tD = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
        "\n",
        "\t\t\t# loop over the upper triangular of the distance matrix\n",
        "\t\t\tfor i in range(0, D.shape[0]):\n",
        "\t\t\t\tfor j in range(i + 1, D.shape[1]):\n",
        "\t\t\t\t\t# check to see if the distance between any two\n",
        "\t\t\t\t\t# centroid pairs is less than the configured number\n",
        "\t\t\t\t\t# of pixels\n",
        "\t\t\t\t\tif D[i, j] < config.MIN_DISTANCE:\n",
        "\t\t\t\t\t\t# update our violation set with the indexes of\n",
        "\t\t\t\t\t\t# the centroid pairs\n",
        "\t\t\t\t\t\tviolate.add(i)\n",
        "\t\t\t\t\t\tviolate.add(j)\n",
        "\n",
        "\t\t# loop over the results\n",
        "\t\t\tfor (i, (prob, bbox, centroid)) in enumerate(results):\n",
        "\t\t\t\t# extract the bounding box and centroid coordinates, then\n",
        "\t\t\t\t# initialize the color of the annotation\n",
        "\t\t\t\t(startX, startY, endX, endY) = bbox\n",
        "\t\t\t\t(cX, cY) = centroid\n",
        "\t\t\t\tcolor = (0, 255, 0)\n",
        "\n",
        "\t\t\t\t# if the index pair exists within the violation set, then\n",
        "\t\t\t\t# update the color\n",
        "\t\t\t\tif i in violate:\n",
        "\t\t\t\t\tcolor = (0, 0, 255)\n",
        "\n",
        "\t\t\t\t# draw (1) a bounding box around the person and (2) the\n",
        "\t\t\t\t# centroid coordinates of the person,\n",
        "\t\t\t\tcv2.rectangle(frame, (startX-10, startY-25), (endX+10, endY+25), color, 1)\n",
        "\t\t\t\t#cv2.circle(frame, (cX, cY), 5, color, 1)\n",
        "\n",
        "\t\t\t# draw the total number of social distancing violations on the\n",
        "\t\t\t# output frame\n",
        "\t\t\ttext_ = \"Social Distancing Violations: {}\".format(len(violate))\n",
        "\t\t\tcv2.putText(frame, text_, (10, frame.shape[0] - 25),\n",
        "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 2)\n",
        "\n",
        "\telse:\n",
        "\t\tcontinue\n",
        " st.image(frame, width=640)\n",
        "  st.write('### ' + label)\n",
        "\n",
        "\tif grad_cam_button:\n",
        "        data = ([face], None)\n",
        "        explainer = GradCAM()\n",
        "        grad_cam_grid = explainer.explain(\n",
        "            data, model, class_index=predicted_class, layer_name=\"Conv_1\"\n",
        "        )\n",
        "        st.image(grad_cam_grid)\n",
        "\n",
        "    if occlusion_sensitivity_button:\n",
        "        data = ([face], None)\n",
        "        explainer = OcclusionSensitivity()\n",
        "        sensitivity_occlusion_grid = explainer.explain(data, model, predicted_class, patch_size_value)\n",
        "        st.image(sensitivity_occlusion_grid)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}